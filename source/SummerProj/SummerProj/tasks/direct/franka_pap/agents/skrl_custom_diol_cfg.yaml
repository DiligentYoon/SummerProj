# Seed for random process
seed: 42

models:
  high_level:
    q_network:
      _target_: SummerProj.tasks.direct.franka_pap.models.custom_diol_net.FrankaQNetwork
      # FrankaQNetwork의 __init__에 전달할 파라미터들
      features: [256, 128, 64]
    target_q_network:
      _target_: SummerProj.tasks.direct.franka_pap.models.custom_diol_net.FrankaQNetwork
      features: [256, 128, 64]
  
  low_level:
    separate: True
    policy:
      _target_: SummerProj.tasks.direct.franka_pap.models.custom_diol_net.FrankaDeterministicPolicy
      # FrankaDeterministicPolicy의 __init__에 전달할 파라미터들
      encoder_features: [256, 128]
      policy_features: [64]
      clip_actions: False
    critic_1:
      _target_: SummerProj.tasks.direct.franka_pap.models.custom_diol_net.FrankaValue
      encoder_features: [256, 128]
      value_features: [64]
    critic_2:
      _target_: SummerProj.tasks.direct.franka_pap.models.custom_diol_net.FrankaValue
      encoder_features: [256, 128]
      value_features: [64]
    target_critic_1:
      _target_: SummerProj.tasks.direct.franka_pap.models.custom_diol_net.FrankaValue
      encoder_features: [256, 128]
      value_features: [64]
    target_critic_2:
      _target_: SummerProj.tasks.direct.franka_pap.models.custom_diol_net.FrankaValue
      encoder_features: [256, 128]
      value_features: [64]


# Rollout memory
# https://skrl.readthedocs.io/en/latest/api/memories/random.html
memory:
  # 2-1. 고수준 에이전트를 위한 리플레이 버퍼
  high_level:
    memory_size: 100000

  # 2-2. 저수준 에이전트를 위한 리플레이 버퍼
  low_level:
    memory_size: 1000000


# https://skrl.readthedocs.io/en/latest/api/agents/ppo.html
agent:
  # 3-1. 고수준 에이전트 (커스텀 DIOL 에이전트)
  high_level:
    class: DIOL
    gradient_steps: 1
    batch_size: 64

    discount_factor: 0.99 # 감가율 (gamma)
    polyak: 0.005

    learning_rate_scheduler: KLAdaptiveLR
    learning_rate_scheduler_kwargs:
      kl_threshold: 0.008

    state_preprocessor: RunningStandardScaler
    state_preprocessor_kwargs: null  # null로 두면 skrl/runner가 자동으로 채워줌

    random_timesteps: 1000 # 초기 랜덤 탐험 스텝
    learning_starts: 1000  # 학습 시작 전 최소 경험 수

    exploration: 
        "initial_epsilon": 1.0,       # initial epsilon for epsilon-greedy exploration
        "final_epsilon": 1e-5,        # final epsilon for epsilon-greedy exploration
        "timesteps": 1000,            # timesteps for epsilon-greedy decay
    
    experiment:
      directory: "franka_pap"
      experiment_name: ""
      write_interval: auto
      checkpoint_interval: auto

  # 3-2. 저수준 에이전트
  low_level:
    class: DDPG
    gradient_steps: 1
    batch_size: 64

    discount_factor: 0.99 # 감가율 (gamma)
    polyak: 0.005

    actor_learning_rate: 1.0e-4
    critic_learning_rate: 1.0e-4
    learning_rate_scheduler: KLAdaptiveLR
    learning_rate_scheduler_kwargs:
      kl_threshold: 0.008

    state_preprocessor: RunningStandardScaler
    state_preprocessor_kwargs: null

    random_timesteps: 1000 # 초기 랜덤 탐험 스텝
    learning_starts: 1000  # 학습 시작 전 최소 경험 수

    grad_norm_clip: 1.0

    # logging and checkpoint
    experiment:
      directory: "franka_pap"
      experiment_name: ""
      write_interval: auto
      checkpoint_interval: auto


# Trainer
# https://skrl.readthedocs.io/en/latest/api/trainers/
trainer:
  _target_: SummerProj.tasks.direct.franka_pap.trainers.trainer.HRLTrainer
  timesteps: null
  epoch_interval: 1
  cycle_interval: 50
  episode_interval: 16
  # AAES (Auto-Adjusting Exploration Strategy)
  aaes_kwargs:
    initial_std: 0.5
    min_std: 0.05
    max_std: 1.0
    reduction_factor: 0.99
    increase_factor: 1.01
    success_threshold_high: 0.8
    success_threshold_low: 0.2
  # HER 관련 설정
  her_kwargs:
    k_ratio: 4
    strategy: "future" # future or episode
    low_threshold: 0.05
    high_threshold: 0.1